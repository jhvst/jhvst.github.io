@article{AffineLogicFoShulma2022,
  abstract = {<jats:title>Abstract</jats:title><jats:p>We show that numerous distinctive concepts of constructive mathematics arise automatically from an \textquotedblleft{}antithesis\textquotedblright{} translation of affine logic into intuitionistic logic via a Chu/Dialectica construction. This includes apartness relations, complemented subsets, anti-subgroups and anti-ideals, strict and non-strict order pairs, cut-valued metrics, and apartness spaces. We also explain the constructive bifurcation of some classical concepts using the choice between multiplicative and additive affine connectives. Affine logic and the antithesis construction thus systematically \textquotedblleft{}constructivize\textquotedblright{} classical definitions, handling the resulting bookkeeping automatically.</jats:p>},
  author = {SHULMAN, MICHAEL},
  doi = {10.1017/bsl.2022.28},
  issue = {3},
  journal = {The Bulletin of Symbolic Logic},
  language = {en},
  month = {9},
  pages = {327--386},
  publisher = {Cambridge University Press (CUP)},
  title = {AFFINE LOGIC FOR CONSTRUCTIVE MATHEMATICS},
  url = {http://dx.doi.org/10.1017/bsl.2022.28},
  volume = {28},
  year = {2022},
}

@inproceedings{FireironHagedo2020,
  author = {Hagedorn, Bastian and Elliott, Archibald Samuel and Barthels, Henrik and Bodik, Rastislav and Grover, Vinod},
  booktitle = {PACT '20: International Conference on Parallel Architectures and Compilation Techniques},
  doi = {10.1145/3410463.3414632},
  journal = {Proceedings of the ACM International Conference on Parallel Architectures and Compilation Techniques},
  month = {9},
  publisher = {ACM},
  title = {Fireiron: A Data-Movement-Aware Scheduling Language for GPUs},
  url = {http://dx.doi.org/10.1145/3410463.3414632},
  venue = {Virtual Event GA USA},
  year = {2020},
}

@article{ApexTheAplPRobert1997,
  author = {Robert Bernecky},
  title = {APEX, the APL parallel executor},
  year = {1997},
}

@inproceedings{HalideRagan2013,
  abstract = {<jats:p>Image processing pipelines combine the challenges of stencil computations and stream programs. They are composed of large graphs of different stencil stages, as well as complex reductions, and stages with global or data-dependent access patterns. Because of their complex structure, the performance difference between a naive implementation of a pipeline and an optimized one is often an order of magnitude. Efficient implementations require optimization of both parallelism and locality, but due to the nature of stencils, there is a fundamental tension between parallelism, locality, and introducing redundant recomputation of shared values.</jats:p>
          <jats:p>We present a systematic model of the tradeoff space fundamental to stencil pipelines, a schedule representation which describes concrete points in this space for each stage in an image processing pipeline, and an optimizing compiler for the Halide image processing language that synthesizes high performance implementations from a Halide algorithm and a schedule. Combining this compiler with stochastic search over the space of schedules enables terse, composable programs to achieve state-of-the-art performance on a wide range of real image processing pipelines, and across different hardware architectures, including multicores with SIMD, and heterogeneous CPU+GPU execution. From simple Halide programs written in a few hours, we demonstrate performance up to 5x faster than hand-tuned C, intrinsics, and CUDA implementations optimized by experts over weeks or months, for image processing applications beyond the reach of past automatic compilers.</jats:p>},
  author = {Ragan-Kelley, Jonathan and Barnes, Connelly and Adams, Andrew and Paris, Sylvain and Durand, Fr\'{e}do and Amarasinghe, Saman},
  booktitle = {PLDI '13: ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/2491956.2462176},
  issue = {6},
  journal = {Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  language = {en},
  month = {6},
  pages = {519--530},
  publisher = {ACM},
  title = {Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines},
  url = {http://dx.doi.org/10.1145/2491956.2462176},
  venue = {Seattle Washington USA},
  volume = {48},
  year = {2013},
}

@article{ProgrammingInJayC1999,
  author = {Jay, C. Barry},
  doi = {10.1007/s100090050037},
  issue = {3},
  journal = {International Journal on Software Tools for Technology Transfer (STTT)},
  month = {11},
  pages = {307--315},
  publisher = {Springer Science and Business Media LLC},
  title = {Programming in FISh},
  url = {http://dx.doi.org/10.1007/s100090050037},
  volume = {2},
  year = {1999},
}

@inproceedings{BreakingTheCoJangda2022,
  author = {Jangda, Abhinav and Huang, Jun and Liu, Guodong and Sabet, Amir Hossein Nodehi and Maleki, Saeed and Miao, Youshan and Musuvathi, Madanlal and Mytkowicz, Todd and Saarikivi, Olli},
  booktitle = {ASPLOS '22: 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
  doi = {10.1145/3503222.3507778},
  journal = {Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
  month = {2},
  publisher = {ACM},
  title = {Breaking the computation and communication abstraction barrier in distributed machine learning workloads},
  url = {http://dx.doi.org/10.1145/3503222.3507778},
  venue = {Lausanne Switzerland},
  year = {2022},
}

@inproceedings{HighPerformancHagedo2018,
  author = {Hagedorn, Bastian and Stoltzfus, Larisa and Steuwer, Michel and Gorlatch, Sergei and Dubach, Christophe},
  booktitle = {CGO '18: 16th Annual IEEE/ACM International Symposium on Code Generation and Optimization},
  doi = {10.1145/3168824},
  journal = {Proceedings of the 2018 International Symposium on Code Generation and Optimization},
  month = {2},
  publisher = {ACM},
  title = {High performance stencil code generation with Lift},
  url = {http://dx.doi.org/10.1145/3168824},
  venue = {Vienna Austria},
  year = {2018},
}

@inproceedings{AplOnGpusAHenrik2016,
  author = {Henriksen, Troels and Dybdal, Martin and Urms, Henrik and Kiehn, Anna Sofie and Gavin, Daniel and Abelskov, Hjalte and Elsman, Martin and Oancea, Cosmin},
  booktitle = {ICFP'16: ACM SIGPLAN International Conference on Functional Programming},
  doi = {10.1145/2975991.2975997},
  journal = {Proceedings of the 5th International Workshop on Functional High-Performance Computing},
  month = {9},
  publisher = {ACM},
  title = {APL on GPUs: a TAIL from the past, scribbled in Futhark},
  url = {http://dx.doi.org/10.1145/2975991.2975997},
  venue = {Nara Japan},
  year = {2016},
}

@inproceedings{LegateNumpyBauer2019,
  author = {Bauer, Michael and Garland, Michael},
  booktitle = {SC '19: The International Conference for High Performance Computing, Networking, Storage, and Analysis},
  doi = {10.1145/3295500.3356175},
  journal = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  month = {11},
  publisher = {ACM},
  title = {Legate NumPy: Accelerated and Distributed Array Computing},
  url = {http://dx.doi.org/10.1145/3295500.3356175},
  venue = {Denver Colorado},
  year = {2019},
}

@inproceedings{GrowingSolverTorlak2013,
  author = {Torlak, Emina and Bodik, Rastislav},
  booktitle = {SPLASH '13: Conference on Systems, Programming, and Applications: Software for Humanity},
  doi = {10.1145/2509578.2509586},
  journal = {Proceedings of the 2013 ACM international symposium on New ideas, new paradigms, and reflections on programming \textbackslash{}\&amp; software},
  month = {10},
  publisher = {ACM},
  title = {Growing solver-aided languages with rosette},
  url = {http://dx.doi.org/10.1145/2509578.2509586},
  venue = {Indianapolis Indiana USA},
  year = {2013},
}

@inproceedings{GpuverifyBetts2012,
  author = {Betts, Adam and Chong, Nathan and Donaldson, Alastair and Qadeer, Shaz and Thomson, Paul},
  booktitle = {SPLASH '12: Conference on Systems, Programming, and Applications: Software for Humanity},
  doi = {10.1145/2384616.2384625},
  journal = {Proceedings of the ACM international conference on Object oriented programming systems languages and applications},
  month = {10},
  publisher = {ACM},
  title = {GPUVerify},
  url = {http://dx.doi.org/10.1145/2384616.2384625},
  venue = {Tucson Arizona USA},
  year = {2012},
}

@article{NamedTensorNoChiang2021,
  abstract = {We propose a notation for tensors with named axes, which relieves the author, reader, and future implementers of machine learning models from the burden of keeping track of the order of axes and the purpose of each. The notation makes it easy to lift operations on low-order tensors to higher order ones, for example, from images to minibatches of images, or from an attention mechanism to multiple attention heads.   After a brief overview and formal definition of the notation, we illustrate it through several examples from modern machine learning, from building blocks like attention and convolution to full models like Transformers and LeNet. We then discuss differential calculus in our notation and compare with some alternative notations. Our proposals build on ideas from many previous papers and software libraries. We hope that our notation will encourage more authors to use named tensors, resulting in clearer papers and more precise implementations.},
  archiveprefix = {arXiv},
  author = {Chiang, David and Rush, Alexander M. and Barak, Boaz},
  eprint = {2102.13196v3},
  file = {2102.13196v3.pdf},
  month = {Feb},
  note = {TMLR, January 2023},
  primaryclass = {cs.LG},
  title = {Named Tensor Notation},
  url = {http://arxiv.org/abs/2102.13196v3},
  year = {2021},
}

@inproceedings{TestCaseReducDonald2021,
  author = {Donaldson, Alastair F. and Thomson, Paul and Teliman, Vasyl and Milizia, Stefano and Maselco, Andr\'{e} Perez and Karpi\'{n}ski, Antoni},
  booktitle = {PLDI '21: 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  doi = {10.1145/3453483.3454092},
  journal = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  month = {6},
  publisher = {ACM},
  title = {Test-case reduction and deduplication almost for free with transformation-based compiler testing},
  url = {http://dx.doi.org/10.1145/3453483.3454092},
  venue = {Virtual Canada},
  year = {2021},
}

@inproceedings{GpuProgrammingHolk2013,
  author = {Holk, Eric and Pathirage, Milinda and Chauhan, Arun and Lumsdaine, Andrew and Matsakis, Nicholas D.},
  booktitle = {2013 IEEE International Symposium on Parallel \& Distributed Processing, Workshops and Phd Forum (IPDPSW)},
  doi = {10.1109/ipdpsw.2013.173},
  journal = {2013 IEEE International Symposium on Parallel \textbackslash{}\&amp; Distributed Processing, Workshops and Phd Forum},
  month = {5},
  publisher = {IEEE},
  title = {GPU Programming in Rust: Implementing High-Level Abstractions in a Systems-Level Language},
  url = {http://dx.doi.org/10.1109/ipdpsw.2013.173},
  venue = {Cambridge, MA, USA},
  year = {2013},
}

@article{Idris2QuantiBrady2021,
  abstract = {Dependent types allow us to express precisely what a function is intended to do. Recent work on Quantitative Type Theory (QTT) extends dependent type systems with linearity, also allowing precision in expressing when a function can run. This is promising, because it suggests the ability to design and reason about resource usage protocols, such as we might find in distributed and concurrent programming, where the state of a communication channel changes throughout program execution. As yet, however, there has not been a full-scale programming language with which to experiment with these ideas. Idris 2 is a new version of the dependently typed language Idris, with a new core language based on QTT, supporting linear and dependent types. In this paper, we introduce Idris 2, and describe how QTT has influenced its design. We give examples of the benefits of QTT in practice including: expressing which data is erased at run time, at the type level; and, resource tracking in the type system leading to type-safe concurrent programming with session types.},
  archiveprefix = {arXiv},
  author = {Brady, Edwin},
  eprint = {2104.00480v1},
  file = {2104.00480v1.pdf},
  month = {Apr},
  primaryclass = {cs.PL},
  title = {Idris 2: Quantitative Type Theory in Practice},
  url = {http://arxiv.org/abs/2104.00480v1},
  year = {2021},
}

@inproceedings{ParallelScanASinkar2022,
  author = {\v{S}inkarovs, Artjoms and Scholz, Sven-Bodo},
  booktitle = {ARRAY '22: 8th ACM SIGPLAN International Workshop on Libraries, Languages and Compilers for Array Programming},
  doi = {10.1145/3520306.3534500},
  journal = {Proceedings of the 8th ACM SIGPLAN International Workshop on Libraries, Languages and Compilers for Array Programming},
  month = {6},
  publisher = {ACM},
  title = {Parallel scan as a multidimensional array problem},
  url = {http://dx.doi.org/10.1145/3520306.3534500},
  venue = {San Diego CA USA},
  year = {2022},
}

@article{PolynomialSizeShkara2009,
  abstract = {<jats:p>We present a size-aware type system for first-order shapely function
definitions. Here, a function definition is called shapely when the size of the
result is determined exactly by a polynomial in the sizes of the arguments.
Examples of shapely function definitions may be implementations of matrix
multiplication and the Cartesian product of two lists. The type system is
proved to be sound w.r.t. the operational semantics of the language. The type
checking problem is shown to be undecidable in general. We define a natural
syntactic restriction such that the type checking becomes decidable, even
though size polynomials are not necessarily linear or monotonic. Furthermore,
we have shown that the type-inference problem is at least semi-decidable (under
this restriction). We have implemented a procedure that combines run-time
testing and type-checking to automatically obtain size dependencies. It
terminates on total typable function definitions.</jats:p>},
  author = {Shkaravska, Olha and van Eekelen, Marko and van Kesteren, Ron},
  doi = {10.2168/lmcs-5(2:10)2009},
  journal = {Logical Methods in Computer Science},
  language = {en},
  month = {5},
  publisher = {Centre pour la Communication Scientifique Directe (CCSD)},
  title = {Polynomial Size Analysis of First-Order Shapely Functions},
  url = {http://dx.doi.org/10.2168/lmcs-5(2:10)2009},
  volume = {Volume 5, Issue 2},
  year = {2009},
}

@inproceedings{BarrierInvariaChong2013,
  author = {Chong, Nathan and Donaldson, Alastair F. and Kelly, Paul H.J. and Ketema, Jeroen and Qadeer, Shaz},
  booktitle = {SPLASH '13: Conference on Systems, Programming, and Applications: Software for Humanity},
  doi = {10.1145/2509136.2509517},
  journal = {Proceedings of the 2013 ACM SIGPLAN international conference on Object oriented programming systems languages \textbackslash{}\&amp; applications},
  month = {10},
  publisher = {ACM},
  title = {Barrier Invariants: A Shared State Abstraction for the Analysis of Data-Dependent GPU Kernels},
  url = {http://dx.doi.org/10.1145/2509136.2509517},
  venue = {Indianapolis Indiana USA},
  year = {2013},
}

@article{IntroductionToShiver2019,
  abstract = {Remora is a higher-order, rank-polymorphic array-processing programming language, in the same general class of languages as APL and J. It is intended for writing programs to be executed on parallel hardware.   We provide an example-driven introduction to the language, and its general computational model, originally developed by Iverson for APL. We begin with Dynamic Remora, a variant of the language with a dynamic type system (as in Scheme or Lisp), to introduce the fundamental computational mechanisms of the language, then shift to Explicitly Typed Remora, a variant of the language with a static, dependent type system that permits the shape of the arrays being computed to be captured at compile time.   This article can be considered an introduction to the general topic of the rank-polymorphic array-processing computational model, above and beyond the specific details of the Remora language.   We do not address the details of type inference in Remora, that is, the assignment of explicit types to programs written without such annotations; this is ongoing research.},
  archiveprefix = {arXiv},
  author = {Shivers, Olin and Slepak, Justin and Manolios, Panagiotis},
  eprint = {1912.13451v2},
  file = {1912.13451v2.pdf},
  month = {Dec},
  primaryclass = {cs.PL},
  title = {Introduction to Rank-polymorphic Programming in Remora (Draft)},
  url = {http://arxiv.org/abs/1912.13451v2},
  year = {2019},
}

@article{ArrayProgrammiHarris2020,
  abstract = {<jats:title>Abstract</jats:title><jats:p>Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves<jats:sup>1</jats:sup>and in the first imaging of a black hole<jats:sup>2</jats:sup>. Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.</jats:p>},
  author = {Harris, Charles R. and Millman, K. Jarrod and van der Walt, St\'{e}fan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and del R\'{\i}o, Jaime Fern\'{a}ndez and Wiebe, Mark and Peterson, Pearu and G\'{e}rard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
  doi = {10.1038/s41586-020-2649-2},
  issue = {7825},
  journal = {Nature},
  language = {en},
  month = {9},
  pages = {357--362},
  publisher = {Springer Science and Business Media LLC},
  title = {Array programming with NumPy},
  url = {http://dx.doi.org/10.1038/s41586-020-2649-2},
  volume = {585},
  year = {2020},
}

@article{ParallelAlgebrXieN2021,
  abstract = {Algebraic effects and handlers support composable and structured control-flow abstraction. However, existing designs of algebraic effects often require effects to be executed sequentially. This paper studies parallel algebraic effect handlers. In particular, we formalize \lbrace{}\textbackslash{}lambda\rbrace{}p, an untyped lambda calculus which models two key features, effect handlers and parallelizable computations, the latter of which takes the form of a for expression as inspired by the Dex programming language. We present various interesting examples expressible in our calculus, and provide a Haskell implementation. We hope this paper provides a basis for future designs and implementations of parallel algebraic effect handlers.},
  archiveprefix = {arXiv},
  author = {Xie, Ningning and Johnson, Daniel D. and Maclaurin, Dougal and Paszke, Adam},
  eprint = {2110.07493v1},
  file = {2110.07493v1.pdf},
  month = {Oct},
  primaryclass = {cs.PL},
  title = {Parallel Algebraic Effect Handlers},
  url = {http://arxiv.org/abs/2110.07493v1},
  year = {2021},
}

@inproceedings{CopperheadCatanz2011,
  author = {Catanzaro, Bryan and Garland, Michael and Keutzer, Kurt},
  booktitle = {PPoPP '11: ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
  doi = {10.1145/1941553.1941562},
  journal = {Proceedings of the 16th ACM symposium on Principles and practice of parallel programming},
  month = {2},
  publisher = {ACM},
  title = {Copperhead},
  url = {http://dx.doi.org/10.1145/1941553.1941562},
  venue = {San Antonio TX USA},
  year = {2011},
}

@article{TowardsHaskellEpstei2012,
  abstract = {<jats:p>We present Cloud Haskell, a domain-specific language for developing programs for a distributed computing environment. Implemented as a shallow embedding in Haskell, it provides a message-passing communication model, inspired by Erlang, without introducing incompatibility with Haskell's established shared-memory concurrency. A key contribution is a method for serializing function closures for transmission across the network. Cloud Haskell has been implemented; we present example code and some preliminary performance measurements.</jats:p>},
  author = {Epstein, Jeff and Black, Andrew P. and Peyton-Jones, Simon},
  doi = {10.1145/2096148.2034690},
  issue = {12},
  journal = {ACM SIGPLAN Notices},
  language = {en},
  month = {1},
  pages = {118--129},
  publisher = {Association for Computing Machinery (ACM)},
  title = {Towards Haskell in the cloud},
  url = {http://dx.doi.org/10.1145/2096148.2034690},
  volume = {46},
  year = {2012},
}

@article{AGradedDependChoudh2021,
  abstract = {<jats:p>Graded Type Theory provides a mechanism to track and reason about resource usage in type systems. In this paper, we develop GraD, a novel version of such a graded dependent type system that includes functions, tensor products, additive sums, and a unit type. Since standard operational semantics is resource-agnostic, we develop a heap-based operational semantics and prove a soundness theorem that shows correct accounting of resource usage. Several useful properties, including the standard type soundness theorem, non-interference of irrelevant resources in computation and single pointer property for linear resources, can be derived from this theorem. We hope that our work will provide a base for integrating linearity, irrelevance and dependent types in practical programming languages like Haskell.</jats:p>},
  author = {Choudhury, Pritam and Eades III, Harley and Eisenberg, Richard A. and Weirich, Stephanie},
  doi = {10.1145/3434331},
  issue = {POPL},
  journal = {Proceedings of the ACM on Programming Languages},
  language = {en},
  month = {1},
  pages = {1--32},
  publisher = {Association for Computing Machinery (ACM)},
  title = {A graded dependent type system with a usage-aware semantics},
  url = {http://dx.doi.org/10.1145/3434331},
  volume = {5},
  year = {2021},
}

@inproceedings{AConstraintBaLeeW2019,
  author = {Lee, Wonchan and Papadakis, Manolis and Slaughter, Elliott and Aiken, Alex},
  booktitle = {SC '19: The International Conference for High Performance Computing, Networking, Storage, and Analysis},
  doi = {10.1145/3295500.3356199},
  journal = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  month = {11},
  publisher = {ACM},
  title = {A constraint-based approach to automatic data partitioning for distributed memory execution},
  url = {http://dx.doi.org/10.1145/3295500.3356199},
  venue = {Denver Colorado},
  year = {2019},
}

@article{QuantitativePrOrchar2019,
  abstract = {<jats:p>In programming, some data acts as a resource (e.g., file handles, channels) subject to usage constraints. This poses a challenge to software correctness as most languages are agnostic to constraints on data. The approach of linear types provides a partial remedy, delineating data into resources to be used but never copied or discarded, and unconstrained values. Bounded Linear Logic provides a more fine-grained approach, quantifying non-linear use via an indexed-family of modalities. Recent work on coeffect types generalises this idea to graded comonads, providing type systems which can capture various program properties. Here, we propose the umbrella notion of graded modal types, encompassing coeffect types and dual notions of type-based effect reasoning via graded monads. In combination with linear and indexed types, we show that graded modal types provide an expressive type theory for quantitative program reasoning, advancing the reach of type systems to capture and verify a broader set of program properties. We demonstrate this approach via a type system embodied in a fully-fledged functional language called Granule, exploring various examples.</jats:p>},
  author = {Orchard, Dominic and Liepelt, Vilem-Benjamin and Eades III, Harley},
  doi = {10.1145/3341714},
  issue = {ICFP},
  journal = {Proceedings of the ACM on Programming Languages},
  language = {en},
  month = {7},
  pages = {1--30},
  publisher = {Association for Computing Machinery (ACM)},
  title = {Quantitative program reasoning with graded modal types},
  url = {http://dx.doi.org/10.1145/3341714},
  volume = {3},
  year = {2019},
}

@inproceedings{YourComputerIBauman2009,
  abstract = {We argue that a new OS for a multicore machine should be designed ground-up as a distributed system, using concepts from that field. Modern hardware resembles a networked system even more than past large multiprocessors: in addition to familiar latency effects, it exhibits node heterogeneity and dynamic membership changes.

Cache coherence protocols encourage OS designers to selectively ignore this, except for limited performance reasons. Commodity OS designs have mostly assumed fixed, uniform CPU architectures and memory systems.},
  author = {Baumann, Andrew and Peter, Simon and Sch\"{u}pbach, Adrian and Singhania, Akhilesh and Roscoe, Timothy and Barham, Paul and Isaacs, Rebecca},
  booktitle = {12th Workshop on Hot Topics in Operating Systems},
  month = {May},
  publisher = {USENIX},
  title = {Your Computer is Already A Distributed System. Why Isn't Your OS?},
  url = {https://www.microsoft.com/en-us/research/publication/your-computer-is-already-a-distributed-system-why-isnt-your-os/},
  year = {2009},
}

@article{GenericFunctioElliot2017,
  abstract = {<jats:p>
            Parallel programming, whether imperative or functional, has long focused on arrays as the central data type. Meanwhile, typed functional programming has explored a variety of data types, including lists and various forms of trees.
            <jats:italic>Generic</jats:italic>
            functional programming decomposes these data types into a small set of fundamental building blocks: sum, product, composition, and their associated identities. Definitions over these few fundamental type constructions then automatically assemble into algorithms for an infinite variety of data types\textemdash{}some familiar and some new. This paper presents generic functional formulations for two important and well-known classes of parallel algorithms: parallel scan (generalized prefix sum) and fast Fourier transform (FFT). Notably, arrays play no role in these formulations. Consequent benefits include a simpler and more compositional style, much use of common algebraic patterns and freedom from possibility of run-time indexing errors. The functional generic style also clearly reveals deep commonality among what otherwise appear to be quite different algorithms. Instantiating the generic formulations, two well-known algorithms for each of parallel scan and FFT naturally emerge, as well as two possibly new algorithms.
          </jats:p>},
  author = {Elliott, Conal},
  doi = {10.1145/3110251},
  issue = {ICFP},
  journal = {Proceedings of the ACM on Programming Languages},
  language = {en},
  month = {8},
  pages = {1--25},
  publisher = {Association for Computing Machinery (ACM)},
  title = {Generic functional parallel algorithms: scan and FFT},
  url = {http://dx.doi.org/10.1145/3110251},
  volume = {1},
  year = {2017},
}

@article{VerifiedTensorLiuA2022,
  abstract = {<jats:p>We present a lightweight Coq framework for optimizing tensor kernels written in a pure, functional array language. Optimizations rely on user scheduling using series of verified, semantics-preserving rewrites. Unusually for compilation targeting imperative code with arrays and nested loops, all rewrites are source-to-source within a purely functional language. Our language comprises a set of core constructs for expressing high-level computation detail and a set of what we call reshape operators, which can be derived from core constructs but trigger low-level decisions about storage patterns and ordering. We demonstrate that not only is this system capable of deriving the optimizations of existing state-of-the-art languages like Halide and generating comparably performant code, it is also able to schedule a family of useful program transformations beyond what is reachable in Halide.</jats:p>},
  author = {Liu, Amanda and Bernstein, Gilbert Louis and Chlipala, Adam and Ragan-Kelley, Jonathan},
  doi = {10.1145/3498717},
  issue = {POPL},
  journal = {Proceedings of the ACM on Programming Languages},
  language = {en},
  month = {1},
  pages = {1--28},
  publisher = {Association for Computing Machinery (ACM)},
  title = {Verified tensor-program optimization via high-level scheduling rewrites},
  url = {http://dx.doi.org/10.1145/3498717},
  volume = {6},
  year = {2022},
}

@inproceedings{UniquenessAndGordon2012,
  author = {Gordon, Colin S. and Parkinson, Matthew J. and Parsons, Jared and Bromfield, Aleks and Duffy, Joe},
  booktitle = {SPLASH '12: Conference on Systems, Programming, and Applications: Software for Humanity},
  doi = {10.1145/2384616.2384619},
  journal = {Proceedings of the ACM international conference on Object oriented programming systems languages and applications},
  month = {10},
  publisher = {ACM},
  title = {Uniqueness and reference immutability for safe parallelism},
  url = {http://dx.doi.org/10.1145/2384616.2384619},
  venue = {Tucson Arizona USA},
  year = {2012},
}

@inbook{WarpsAndAtomiBardsl2014,
  author = {Bardsley, Ethel and Donaldson, Alastair F.},
  doi = {10.1007/978-3-319-06200-6\_18},
  isbn = {['9783319061993', '9783319062006']},
  journal = {Lecture Notes in Computer Science},
  pages = {230--245},
  publisher = {Springer International Publishing},
  title = {Warps and Atomics: Beyond Barrier Synchronization in the Verification of GPU Kernels},
  url = {http://dx.doi.org/10.1007/978-3-319-06200-6\_18},
  year = {2014},
}

@inproceedings{IncrementalMaxNiskan2022,
  address = {Dagstuhl, Germany},
  annote = {Keywords: maximum satisfiability, MaxSAT, incremental optimization, API, implicit hitting set approach},
  author = {Niskanen, Andreas and Berg, Jeremias and J\"{a}rvisalo, Matti},
  booktitle = {25th International Conference on Theory and Applications of Satisfiability Testing (SAT 2022)},
  doi = {10.4230/LIPIcs.SAT.2022.14},
  editor = {Meel, Kuldeep S. and Strichman, Ofer},
  isbn = {978-3-95977-242-6},
  issn = {1868-8969},
  pages = {14:1--14:19},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f\lbrace{}\textbackslash{}"u\rbrace{}r Informatik},
  series = {Leibniz International Proceedings in Informatics (LIPIcs)},
  title = {Incremental Maximum Satisfiability},
  url = {https://drops.dagstuhl.de/opus/volltexte/2022/16688},
  volume = {236},
  year = {2022},
}

@inproceedings{ALightweightSTorlak2014,
  abstract = {<jats:p>Solver-aided domain-specific languages (SDSLs) are an emerging class of computer-aided programming systems. They ease the construction of programs by using satisfiability solvers to automate tasks such as verification, debugging, synthesis, and non-deterministic execution. But reducing programming tasks to satisfiability problems involves translating programs to logical constraints, which is an engineering challenge even for domain-specific languages.</jats:p>
          <jats:p>We have previously shown that translation to constraints can be avoided if SDSLs are implemented by (traditional) embedding into a host language that is itself solver-aided. This paper describes how to implement a symbolic virtual machine (SVM) for such a host language. Our symbolic virtual machine is lightweight because it compiles to constraints only a small subset of the host's constructs, while allowing SDSL designers to use the entire language, including constructs for DSL embedding. This lightweight compilation employs a novel symbolic execution technique with two key properties: it produces compact encodings, and it enables concrete evaluation to strip away host constructs that are outside the subset compilable to constraints. Our symbolic virtual machine architecture is at the heart of Rosette, a solver-aided language that is host to several new SDSLs.</jats:p>},
  author = {Torlak, Emina and Bodik, Rastislav},
  booktitle = {PLDI '14: ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/2594291.2594340},
  issue = {6},
  journal = {Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  language = {en},
  month = {6},
  pages = {530--541},
  publisher = {ACM},
  title = {A lightweight symbolic virtual machine for solver-aided host languages},
  url = {http://dx.doi.org/10.1145/2594291.2594340},
  venue = {Edinburgh United Kingdom},
  volume = {49},
  year = {2014},
}

@article{LensesForCompVidela2022,
  abstract = {We implement the semantics of server operations using parameterised lenses. They allow us to define endpoints and extend them using classical lens composition. The parameterised nature of lenses models state updates while the lens laws mimic properties expected from HTTP.   This first approach to server development is extended to use dependent parameterised lenses. An upgrade necessary to model not only endpoints, but entire servers, unlocking the ability to compose them together.},
  archiveprefix = {arXiv},
  author = {Videla, Andre and Capucci, Matteo},
  eprint = {2203.15633v1},
  file = {2203.15633v1.pdf},
  month = {Mar},
  primaryclass = {cs.NI},
  title = {Lenses for Composable Servers},
  url = {http://arxiv.org/abs/2203.15633v1},
  year = {2022},
}

@inbook{TypeSystemsFoMcbrid2022,
  author = {McBride, Conor and Nordvall-Forsberg, Fredrik},
  doi = {10.1142/9789811242380\_0020},
  journal = {Series on Advances in Mathematics for Applied Sciences},
  month = {2},
  pages = {331--345},
  publisher = {WORLD SCIENTIFIC},
  title = {Type systems for programs respecting dimensions},
  url = {http://dx.doi.org/10.1142/9789811242380\_0020},
  year = {2022},
}

@inbook{AplicativeProgGibbon2017,
  author = {Gibbons, Jeremy},
  doi = {10.1007/978-3-662-54434-1\_21},
  isbn = {['9783662544334', '9783662544341']},
  journal = {Programming Languages and Systems},
  month = {3},
  pages = {556--583},
  publisher = {Springer Berlin Heidelberg},
  title = {APLicative Programming with Naperian~Functors},
  url = {http://dx.doi.org/10.1007/978-3-662-54434-1\_21},
  year = {2017},
}

@inproceedings{AcceleratingApGrelck1998,
  author = {Grelck, Clemens and Scholz, Sven-Bodo},
  booktitle = {APL99: 1999 Conference on APL},
  doi = {10.1145/312627.312719},
  journal = {Proceedings of the conference on APL \textbackslash{}textquotesingle 99 : On track to the 21st century: On track to the 21st century},
  month = {12},
  publisher = {ACM},
  title = {Accelerating APL programs with SAC},
  url = {http://dx.doi.org/10.1145/312627.312719},
  venue = {Scranton Pennsylvania USA},
  year = {1998},
}

@article{AFormalDescriFalkof1964,
  author = {Falkoff, A. D. and Iverson, K. E. and Sussenguth, E. H.},
  doi = {10.1147/sj.32.0198},
  issue = {2},
  journal = {IBM Systems Journal},
  pages = {198--261},
  publisher = {IBM},
  title = {A formal description of SYSTEM/360},
  url = {http://dx.doi.org/10.1147/sj.32.0198},
  volume = {3},
  year = {1964},
}

@article{SsaIsFunctionAppel1998,
  author = {Appel, Andrew W.},
  doi = {10.1145/278283.278285},
  issue = {4},
  journal = {ACM SIGPLAN Notices},
  language = {en},
  month = {4},
  pages = {17--20},
  publisher = {Association for Computing Machinery (ACM)},
  title = {SSA is functional programming},
  url = {http://dx.doi.org/10.1145/278283.278285},
  volume = {33},
  year = {1998},
}

@inproceedings{TvmAnAChen2018,
  author = {Chen, Tianqi and Moreau, Thierry and Jiang, Ziheng and Zheng, Lianmin and Yan, Eddie and Shen, Haichen and Cowan, Meghan and Wang, Leyuan and Hu, Yuwei and Ceze, Luis and others, },
  booktitle = {13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18)},
  pages = {578--594},
  title = {TVM: An automated End-to-End optimizing compiler for deep learning},
  year = {2018},
}

@article{HigherRankPolNingni2021,
  author = {Ningning Xie},
  title = {Higher-rank Polymorphism: Type Inference and Extensions},
  year = {2021},
}

@article{FutureDirectioLopes2018,
  abstract = {As software becomes larger, programming languages become higher-level, and processors continue to fail to be clocked faster, we'll increasingly require compilers to reduce code bloat, eliminate abstraction penalties, and exploit interesting instruction sets. At the same time, compiler execution time must not increase too much and also compilers should never produce the wrong output. This paper examines the problem of making optimizing compilers faster, less buggy, and more capable of generating high-quality output.},
  archiveprefix = {arXiv},
  author = {Lopes, Nuno P. and Regehr, John},
  eprint = {1809.02161v1},
  file = {1809.02161v1.pdf},
  month = {Sep},
  primaryclass = {cs.PL},
  title = {Future Directions for Optimizing Compilers},
  url = {http://arxiv.org/abs/1809.02161v1},
  year = {2018},
}

@article{ParallelCodeGMarcel2021,
  author = {Marcel Huijben},
  title = {Parallel Code Generation on the GPU},
  year = {2021},
}

@article{augeas,
  author = {Lutterkort, David},
  title = {AUGEAS - a configuration API},
  url = {https://www.kernel.org/doc/ols/2008/ols2008v2-pages-47-56.pdf},
}

@article{EvidenceBasedKaijan2015,
  author = {Kaijanaho, Antti-Juhani},
  journal = {Jyv\lbrace{}\textbackslash{}textbackslash "a\rbrace{}skyl\lbrace{}\textbackslash{}textbackslash "a\rbrace{} studies in computing},
  number = {222},
  publisher = {University of Jyv\lbrace{}\textbackslash{}"a\rbrace{}skyl\lbrace{}\textbackslash{}"a\rbrace{}},
  title = {Evidence-based programming language design: a philosophical and methodological exploration},
  year = {2015},
}

@article{SinglePassParMerril2016,
  author = {Merrill, Duane and Garland, Michael},
  journal = {NVIDIA, Tech. Rep. NVR-2016-002},
  title = {Single-pass parallel prefix scan with decoupled look-back},
  year = {2016},
}

@inproceedings{GeneratingHighPizzut2021,
  author = {Pizzuti, Federico and Steuwer, Michel and Dubach, Christophe},
  booktitle = {ICFP '21: 26th ACM SIGPLAN International Conference on Functional Programming},
  doi = {10.1145/3471873.3472977},
  journal = {Proceedings of the 9th ACM SIGPLAN International Workshop on Functional High-Performance and Numerical Computing},
  month = {8},
  publisher = {ACM},
  title = {Generating high performance code for irregular data structures using dependent types},
  url = {http://dx.doi.org/10.1145/3471873.3472977},
  venue = {Virtual Republic of Korea},
  year = {2021},
}

@inproceedings{CudaScalableLuebke2008,
  author = {Luebke, David},
  booktitle = {2008 5th IEEE International Symposium on Biomedical Imaging (ISBI 2008)},
  doi = {10.1109/isbi.2008.4541126},
  journal = {2008 5th IEEE International Symposium on Biomedical Imaging: From Nano to Macro},
  month = {5},
  publisher = {IEEE},
  title = {CUDA: Scalable parallel programming for high-performance scientific computing},
  url = {http://dx.doi.org/10.1109/isbi.2008.4541126},
  venue = {Paris, France},
  year = {2008},
}

@article{GettingToThePaszke2021,
  abstract = {<jats:p>We present a novel programming language design that attempts to combine the clarity and safety of high-level functional languages with the efficiency and parallelism of low-level numerical languages. We treat arrays as eagerly-memoized functions on typed index sets, allowing abstract function manipulations, such as currying, to work on arrays. In contrast to composing primitive bulk-array operations, we argue for an explicit nested indexing style that mirrors application of functions to arguments. We also introduce a fine-grained typed effects system which affords concise and automatically-parallelized in-place updates. Specifically, an associative accumulation effect allows reverse-mode automatic differentiation of in-place updates in a way that preserves parallelism. Empirically, we benchmark against the Futhark array programming language, and demonstrate that aggressive inlining and type-driven compilation allows array programs to be written in an expressive, "pointful" style with little performance penalty.</jats:p>},
  archiveprefix = {arXiv},
  author = {Paszke, Adam and Johnson, Daniel D. and Duvenaud, David and Vytiniotis, Dimitrios and Radul, Alexey and Johnson, Matthew J. and Ragan-Kelley, Jonathan and Maclaurin, Dougal},
  doi = {10.1145/3473593},
  eprint = {2104.05372v1},
  file = {2104.05372v1.pdf},
  issue = {ICFP},
  journal = {Proceedings of the ACM on Programming Languages},
  language = {en},
  month = {8},
  pages = {1--29},
  primaryclass = {cs.PL},
  publisher = {Association for Computing Machinery (ACM)},
  title = {Getting to the point: index sets and parallelism-preserving autodiff for pointful array programming},
  url = {http://dx.doi.org/10.1145/3473593},
  volume = {5},
  year = {2021},
}

@article{GpuFirstExTian2023,
  abstract = {Utilizing GPUs is critical for high performance on heterogeneous systems. However, leveraging the full potential of GPUs for accelerating legacy CPU applications can be a challenging task for developers. The porting process requires identifying code regions amenable to acceleration, managing distinct memories, synchronizing host and device execution, and handling library functions that may not be directly executable on the device. This complexity makes it challenging for non-experts to leverage GPUs effectively, or even to start offloading parts of a large legacy application. In this paper, we propose a novel compilation scheme called "GPU First" that automatically compiles legacy CPU applications directly for GPUs without any modification of the application source. Library calls inside the application are either resolved through our partial libc GPU implementation or via automatically generated remote procedure calls to the host. Our approach simplifies the task of identifying code regions amenable to acceleration and enables rapid testing of code modifications on actual GPU hardware in order to guide porting efforts. Our evaluation on two HPC proxy applications with OpenMP CPU and GPU parallelism, four micro benchmarks with originally GPU only parallelism, as well as three benchmarks from the SPEC OMP 2012 suite featuring hand-optimized OpenMP CPU parallelism showcases the simplicity of porting host applications to the GPU. For existing parallel loops, we often match the performance of corresponding manually offloaded kernels, with up to 14.36x speedup on the GPU, validating that our GPU First methodology can effectively guide porting efforts of large legacy applications.},
  archiveprefix = {arXiv},
  author = {Tian, Shilei and Scogland, Tom and Chapman, Barbara and Doerfert, Johannes},
  eprint = {2306.11686v3},
  file = {2306.11686v3.pdf},
  month = {Jun},
  primaryclass = {cs.DC},
  title = {GPU First -- Execution of Legacy CPU Codes on GPUs},
  url = {http://arxiv.org/abs/2306.11686v3},
  year = {2023},
}

@article{SynthesizingOpXieN2022,
  author = {Xie, Ningning and Norman, Tamara and Grewe, Dominik and Vytiniotis, Dimitrios},
  journal = {Proceedings of Machine Learning and Systems},
  pages = {548--566},
  title = {Synthesizing optimal parallelism placement and reduction strategies on hierarchical systems for deep learning},
  volume = {4},
  year = {2022},
}

@inproceedings{InteroperableGHaavis2020,
  author = {Haavisto, Juuso and Riekki, Jukka},
  booktitle = {2020 2nd 6G Wireless Summit (6G SUMMIT)},
  doi = {10.1109/6gsummit49458.2020.9083751},
  journal = {2020 2nd 6G Wireless Summit (6G SUMMIT)},
  month = {3},
  publisher = {IEEE},
  title = {Interoperable GPU Kernels as Latency Improver for MEC},
  url = {http://dx.doi.org/10.1109/6gsummit49458.2020.9083751},
  venue = {Levi, Finland},
  year = {2020},
}

@article{LiquidateYourHandle2020,
  abstract = {<jats:p>Liquid Haskell is an extension to the type system of Haskell that supports formal reasoning about program correctness by encoding logical properties as refinement types. In this article, we show how Liquid Haskell can also be used to reason about program efficiency in the same setting. We use the system's existing verification machinery to ensure that the results of our cost analysis are valid, together with custom invariants for particular program contexts to ensure that the results of our analysis are precise. To illustrate our approach, we analyse the efficiency of a wide range of popular data structures and algorithms, and in doing so, explore various notions of resource usage. Our experience is that reasoning about efficiency in Liquid Haskell is often just as simple as reasoning about correctness, and that the two can naturally be combined.</jats:p>},
  author = {Handley, Martin A. T. and Vazou, Niki and Hutton, Graham},
  doi = {10.1145/3371092},
  issue = {POPL},
  journal = {Proceedings of the ACM on Programming Languages},
  language = {en},
  month = {1},
  pages = {1--27},
  publisher = {Association for Computing Machinery (ACM)},
  title = {Liquidate your assets: reasoning about resource usage in liquid Haskell},
  url = {http://dx.doi.org/10.1145/3371092},
  volume = {4},
  year = {2020},
}

@inproceedings{HowToTakeTheMarsha2022,
  address = {Dagstuhl, Germany},
  annote = {Keywords: linear types, regular types, algebra of programming, derivatives},
  author = {Marshall, Daniel and Orchard, Dominic},
  booktitle = {36th European Conference on Object-Oriented Programming (ECOOP 2022)},
  doi = {10.4230/LIPIcs.ECOOP.2022.5},
  editor = {Ali, Karim and Vitek, Jan},
  isbn = {978-3-95977-225-9},
  issn = {1868-8969},
  pages = {5:1--5:27},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f\lbrace{}\textbackslash{}"u\rbrace{}r Informatik},
  series = {Leibniz International Proceedings in Informatics (LIPIcs)},
  title = {How to Take the Inverse of a Type},
  url = {https://drops.dagstuhl.de/opus/volltexte/2022/16233},
  volume = {222},
  year = {2022},
}

@inproceedings{MappingParalleMogers2022,
  author = {Mogers, Naums and Li, Lu and Radu, Valentin and Dubach, Christophe},
  booktitle = {CC '22: 31st ACM SIGPLAN International Conference on Compiler Construction},
  doi = {10.1145/3497776.3517777},
  journal = {Proceedings of the 31st ACM SIGPLAN International Conference on Compiler Construction},
  month = {3},
  publisher = {ACM},
  title = {Mapping parallelism in a functional IR through constraint satisfaction: a case study on convolution for mobile GPUs},
  url = {http://dx.doi.org/10.1145/3497776.3517777},
  venue = {Seoul South Korea},
  year = {2022},
}

@inproceedings{DistalTheDisYadav2022,
  author = {Yadav, Rohan and Aiken, Alex and Kjolstad, Fredrik},
  booktitle = {PLDI '22: 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  doi = {10.1145/3519939.3523437},
  journal = {Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  month = {6},
  publisher = {ACM},
  title = {DISTAL: the distributed tensor algebra compiler},
  url = {http://dx.doi.org/10.1145/3519939.3523437},
  venue = {San Diego CA USA},
  year = {2022},
}

@article{AlgebraicIdentBird1989,
  author = {Bird, R. S.},
  doi = {10.1093/comjnl/32.2.122},
  issue = {2},
  journal = {The Computer Journal},
  language = {en},
  month = {2},
  pages = {122--126},
  publisher = {Oxford University Press (OUP)},
  title = {Algebraic Identities for Program Calculation},
  url = {http://dx.doi.org/10.1093/comjnl/32.2.122},
  volume = {32},
  year = {1989},
}

@article{ProvablySpaceArora2021,
  abstract = {<jats:p>Because of its many desirable properties, such as its ability to control effects and thus potentially disastrous race conditions, functional programming offers a viable approach to programming modern multicore computers. Over the past decade several parallel functional languages, typically based on dialects of ML and Haskell, have been developed. These languages, however, have traditionally underperformed procedural languages (such as C and Java). The primary reason for this is their hunger for memory, which only grows with parallelism, causing traditional memory management techniques to buckle under increased demand for memory. Recent work opened a new angle of attack on this problem by identifying a memory property of determinacy-race-free parallel programs, called disentanglement, which limits the knowledge of concurrent computations about each other's memory allocations. The work has showed some promise in delivering good time scalability.</jats:p>
          <jats:p>
            In this paper, we present provably space-efficient automatic memory management techniques for determinacy-race-free functional parallel programs, allowing both pure and imperative programs where memory may be destructively updated. We prove that for a program with sequential live memory of
            <jats:italic>R</jats:italic>
            <jats:sup>\ast{}</jats:sup>
            , any
            <jats:italic>P</jats:italic>
            -processor garbage-collected parallel run requires at most
            <jats:italic>O</jats:italic>
            (
            <jats:italic>R</jats:italic>
            <jats:sup>\ast{}</jats:sup>
            \cdot{}
            <jats:italic>P</jats:italic>
            ) memory. We also prove a work bound of
            <jats:italic>O</jats:italic>
            (
            <jats:italic>W</jats:italic>
            +
            <jats:italic>R</jats:italic>
            <jats:sup>\ast{}</jats:sup>
            <jats:italic>P</jats:italic>
            ) for
            <jats:italic>P</jats:italic>
            -processor executions, accounting also for the cost of garbage collection. To achieve these results, we integrate thread scheduling with memory management. The idea is to coordinate memory allocation and garbage collection with thread scheduling decisions so that each processor can allocate memory without synchronization and independently collect a portion of memory by consulting a collection policy, which we formulate. The collection policy is fully distributed and does not require communicating with other processors. We show that the approach is practical by implementing it as an extension to the MPL compiler for Parallel ML. Our experimental results confirm our theoretical bounds and show that the techniques perform and scale well.
          </jats:p>},
  author = {Arora, Jatin and Westrick, Sam and Acar, Umut A.},
  doi = {10.1145/3434299},
  issue = {POPL},
  journal = {Proceedings of the ACM on Programming Languages},
  language = {en},
  month = {1},
  pages = {1--33},
  publisher = {Association for Computing Machinery (ACM)},
  title = {Provably space-efficient parallel functional programming},
  url = {http://dx.doi.org/10.1145/3434299},
  volume = {5},
  year = {2021},
}

@inproceedings{TiramisuAPolBaghda2019,
  abstract = {This paper introduces Tiramisu, a polyhedral framework designed to generate high performance code for multiple platforms including multicores, GPUs, and distributed machines. Tiramisu introduces a scheduling language with novel extensions to explicitly manage the complexities that arise when targeting these systems. The framework is designed for the areas of image processing, stencils, linear algebra and deep learning. Tiramisu has two main features: it relies on a flexible representation based on the polyhedral model and it has a rich scheduling language allowing fine-grained control of optimizations. Tiramisu uses a four-level intermediate representation that allows full separation between the algorithms, loop transformations, data layouts, and communication. This separation simplifies targeting multiple hardware architectures with the same algorithm. We evaluate Tiramisu by writing a set of image processing, deep learning, and linear algebra benchmarks and compare them with state-of-the-art compilers and hand-tuned libraries. We show that Tiramisu matches or outperforms existing compilers and libraries on different hardware architectures, including multicore CPUs, GPUs, and distributed machines.},
  author = {Baghdadi, Riyadh and Ray, Jessica and Romdhane, Malek Ben and Del Sozzo, Emanuele and Akkas, Abdurrahman and Zhang, Yunming and Suriana, Patricia and Kamil, Shoaib and Amarasinghe, Saman},
  booktitle = {Proceedings of the 2019 IEEE/ACM International Symposium on Code Generation and Optimization},
  isbn = {9781728114361},
  keywords = {Code Generation, GPU, Deep Learning, Tensors, Distributed Systems, Polyhedral Model, Code Optimization},
  location = {Washington, DC, USA},
  pages = {193\textendash{}205},
  publisher = {IEEE Press},
  series = {CGO 2019},
  title = {Tiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code},
  year = {2019},
}

@inproceedings{FutharkPurelyHenrik2017,
  author = {Henriksen, Troels and Serup, Niels G. W. and Elsman, Martin and Henglein, Fritz and Oancea, Cosmin E.},
  booktitle = {PLDI '17: ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/3062341.3062354},
  journal = {Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  month = {6},
  publisher = {ACM},
  title = {Futhark: purely functional GPU-programming with nested parallelism and in-place array updates},
  url = {http://dx.doi.org/10.1145/3062341.3062354},
  venue = {Barcelona Spain},
  year = {2017},
}

@article{ADataParallelAaron2019,
  author = {Aaron Hsu},
  title = {A data parallel compiler hosted on the GPU},
  year = {2019},
}

@inproceedings{TowardsSizeDeHenrik2021,
  author = {Henriksen, Troels and Elsman, Martin},
  booktitle = {PLDI '21: 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  doi = {10.1145/3460944.3464310},
  journal = {Proceedings of the 7th ACM SIGPLAN International Workshop on Libraries, Languages and Compilers for Array Programming},
  month = {6},
  publisher = {ACM},
  title = {Towards size-dependent types for array programming},
  url = {http://dx.doi.org/10.1145/3460944.3464310},
  venue = {Virtual Canada},
  year = {2021},
}

@article{OnTheDesignOEremon2023,
  author = {Eremondi, Joseph S.},
  title = {On the design of a gradual dependently typed language for programming},
  year = {2023},
}

@article{doctoral_thesis_mogers,
  author = {Mogers, Naums},
  doi = {10.7488/era/3587},
  title = {Guided rewriting and constraint satisfaction for parallel GPU code generation},
  url = {http://dx.doi.org/10.7488/era/3587},
  year = {2023},
}

@inproceedings{CompilationOnVoette2022,
  author = {Voetter, Robin F. and Huijben, Marcel and Rietveld, Kristian F. D.},
  booktitle = {CF '22: 19th ACM International Conference on Computing Frontiers},
  doi = {10.1145/3528416.3530249},
  journal = {Proceedings of the 19th ACM International Conference on Computing Frontiers},
  month = {5},
  publisher = {ACM},
  title = {Compilation on the GPU?},
  url = {http://dx.doi.org/10.1145/3528416.3530249},
  venue = {Turin Italy},
  year = {2022},
}

@inproceedings{CompilingASubElsman2014,
  author = {Elsman, Martin and Dybdal, Martin},
  booktitle = {PLDI '14: ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/2627373.2627390},
  journal = {Proceedings of ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming},
  month = {6},
  publisher = {ACM},
  title = {Compiling a Subset of APL Into a Typed Intermediate Language},
  url = {http://dx.doi.org/10.1145/2627373.2627390},
  venue = {Edinburgh United Kingdom},
  year = {2014},
}

@article{act2023par,
  author = {Wilson, Paul and Zanasi, Fabio},
  title = {Data-Parallel Algorithms for String Diagrams},
  url = {https://act2023.github.io/papers/paper32.pdf},
}

@inproceedings{AcceleratingHaChakra2011,
  author = {Chakravarty, Manuel M.T. and Keller, Gabriele and Lee, Sean and McDonell, Trevor L. and Grover, Vinod},
  booktitle = {POPL '11: The 38th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  doi = {10.1145/1926354.1926358},
  journal = {Proceedings of the sixth workshop on Declarative aspects of multicore programming},
  month = {1},
  publisher = {ACM},
  title = {Accelerating Haskell array codes with multicore GPUs},
  url = {http://dx.doi.org/10.1145/1926354.1926358},
  venue = {Austin Texas USA},
  year = {2011},
}

@inbook{TheSchoolOfSGibbon2020,
  author = {Gibbons, Jeremy},
  doi = {10.1007/978-3-030-54997-8\_2},
  isbn = {['9783030549961', '9783030549978']},
  journal = {Lecture Notes in Computer Science},
  month = {8},
  pages = {35--53},
  publisher = {Springer International Publishing},
  title = {The School of Squiggol},
  url = {http://dx.doi.org/10.1007/978-3-030-54997-8\_2},
  year = {2020},
}

@article{NotationAsATIverso1980,
  author = {Iverson, Kenneth E.},
  doi = {10.1145/358896.358899},
  issue = {8},
  journal = {Communications of the ACM},
  language = {en},
  month = {8},
  pages = {444--465},
  publisher = {Association for Computing Machinery (ACM)},
  title = {Notation as a tool of thought},
  url = {http://dx.doi.org/10.1145/358896.358899},
  volume = {23},
  year = {1980},
}

@inproceedings{Alive2BoundedLopes2021,
  author = {Lopes, Nuno P. and Lee, Juneyoung and Hur, Chung-Kil and Liu, Zhengyang and Regehr, John},
  booktitle = {PLDI '21: 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  doi = {10.1145/3453483.3454030},
  journal = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  month = {6},
  publisher = {ACM},
  title = {Alive2: bounded translation validation for LLVM},
  url = {http://dx.doi.org/10.1145/3453483.3454030},
  venue = {Virtual Canada},
  year = {2021},
}

@inproceedings{R3d3OptimizedKrolik2021,
  author = {Krolik, Alexander and Verbrugge, Clark and Hendren, Laurie},
  booktitle = {2021 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)},
  doi = {10.1109/cgo51591.2021.9370323},
  journal = {2021 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)},
  month = {2},
  publisher = {IEEE},
  title = {r3d3: Optimized Query Compilation on GPUs},
  url = {http://dx.doi.org/10.1109/cgo51591.2021.9370323},
  venue = {Seoul, Korea (South)},
  year = {2021},
}

@article{ParallelLexingRF2021,
  author = {Voetter, Robin},
  title = {Parallel Lexing, Parsing and Semantic Analysis on the GPU},
  year = {2021},
}

@article{AplSince1978HuiR2020,
  abstract = {<jats:p>
            <jats:italic>The Evolution of APL</jats:italic>
            , the HOPL I paper by Falkoff and Iverson on APL, recounted the fundamental design principles which shaped the implementation of the APL language in 1966, and the early uses and other influences which shaped its first decade of enhancements.
          </jats:p>
          <jats:p>In the 40 years that have elapsed since HOPL I, several dozen APL implementations have come and gone. In the first decade or two, interpreters were typically born and buried along with the hardware or operating system that they were created for. More recently, the use of C as an implementation language provided APL interpreters with greater longevity and portability.</jats:p>
          <jats:p>
            APL started its life on IBM mainframes which were time-shared by multiple users. As the demand for computing resources grew and costs dropped, APL first moved
            <jats:italic>in-house</jats:italic>
            to mainframes, then to
            <jats:italic>mini</jats:italic>
            - and
            <jats:italic>micro</jats:italic>
            -computers. Today, APL runs on PCs and tablets, Apples and Raspberry Pis, smartphones and watches.
          </jats:p>
          <jats:p>The operating systems, and the software application platforms that APL runs on, have evolved beyond recognition. Tools like database systems have taken over many of the tasks that were initially implemented in APL or provided by the APL system, and new capabilities like parallel hardware have also changed the focus of design and implementation efforts through the years.</jats:p>
          <jats:p>The first wave of significant language enhancements occurred shortly after HOPL I, resulting in so-called second-generation APL systems. The most important feature of the second generation is the addition of general arrays\textemdash{}in which any item of an array can be another array\textemdash{}and a number of new functions and operators aligned with, if not always motivated by, the new data structures.</jats:p>
          <jats:p>The majority of implementations followed IBM's path with APL2 \textquotedblleft{}floating\textquotedblright{} arrays; others aligned themselves with SHARP APL and \textquotedblleft{}grounded\textquotedblright{} arrays. While the APL2 style of APL interpreters came to dominate the mainstream of the APL community, two new cousins of APL descended from the SHARP APL family tree: J (created by Iverson and Hui) and k (created by Arthur Whitney).</jats:p>
          <jats:p>We attempt to follow a reasonable number of threads through the last 40 years, to identify the most important factors that have shaped the evolution of APL. We will discuss the details of what we believe are the most significant language features that made it through the occasionally unnatural selection imposed by the loss of habitats that disappeared with hardware, software platforms, and business models.</jats:p>
          <jats:p>The history of APL now spans six decades. It is still the case, as Falkoff and Iverson remarked at the end of the HOPL I paper, that:</jats:p>
          <jats:p>Although this is not the place to discuss the future, it should be remarked that the evolution of APL is far from finished.</jats:p>},
  author = {Hui, Roger K. W. and Kromberg, Morten J.},
  doi = {10.1145/3386319},
  issue = {HOPL},
  journal = {Proceedings of the ACM on Programming Languages},
  language = {en},
  month = {6},
  pages = {1--108},
  publisher = {Association for Computing Machinery (ACM)},
  title = {APL since 1978},
  url = {http://dx.doi.org/10.1145/3386319},
  volume = {4},
  year = {2020},
}

@inproceedings{BewareOfFragmWeng2023,
  author = {Weng, Qizhen and Yang, Lingyun and Yu, Yinghao and Wang, Wei and Tang, Xiaochuan and Yang, Guodong and Zhang, Liping},
  booktitle = {2023 USENIX Annual Technical Conference (USENIX ATC 23)},
  pages = {995--1008},
  title = {Beware of Fragmentation: Scheduling GPU-Sharing Workloads with Fragmentation Gradient Descent},
  year = {2023},
}

@article{DependentlyTypTrojah2009,
  author = {Trojahner, Kai and Grelck, Clemens},
  doi = {10.1016/j.jlap.2009.03.002},
  issue = {7},
  journal = {The Journal of Logic and Algebraic Programming},
  language = {en},
  month = {8},
  pages = {643--664},
  publisher = {Elsevier BV},
  title = {Dependently typed array programs don't go wrong},
  url = {http://dx.doi.org/10.1016/j.jlap.2009.03.002},
  volume = {78},
  year = {2009},
}

@inproceedings{TeilATypeSaRink2019,
  author = {Rink, Norman A. and Castrillon, Jeronimo},
  booktitle = {PLDI '19: 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/3315454.3329959},
  journal = {Proceedings of the 6th ACM SIGPLAN International Workshop on Libraries, Languages and Compilers for Array Programming},
  month = {6},
  publisher = {ACM},
  title = {TeIL: a type-safe imperative tensor intermediate language},
  url = {http://dx.doi.org/10.1145/3315454.3329959},
  venue = {Phoenix AZ USA},
  year = {2019},
}

@article{StagedCompilatKovacs2022,
  abstract = {<jats:p>The aim of staged compilation is to enable metaprogramming in a way such that we  
have guarantees about the well-formedness of code output, and we can also mix  
together object-level and meta-level code in a concise and convenient manner. In  
this work, we observe that two-level type theory (2LTT), a system originally  
devised for the purpose of developing synthetic homotopy theory, also serves as  
a system for staged compilation with dependent types. 2LTT has numerous good  
properties for this use case: it has a concise specification, well-behaved model  
theory, and it supports a wide range of language features both at the object and  
the meta level. First, we give an overview of 2LTT's features and applications  
in staging. Then, we present a staging algorithm and prove its correctness. Our  
algorithm is "staging-by-evaluation", analogously to the technique of  
normalization-by-evaluation, in that staging is given by the evaluation of 2LTT  
syntax in a semantic domain. The staging algorithm together with its correctness  
constitutes a proof of strong conservativity of 2LLT over the object theory. To our  
knowledge, this is the first description of staged compilation which supports  
full dependent types and unrestricted staging for types.</jats:p>},
  author = {Kov\'{a}cs, Andr\'{a}s},
  doi = {10.1145/3547641},
  issue = {ICFP},
  journal = {Proceedings of the ACM on Programming Languages},
  language = {en},
  month = {8},
  pages = {540--569},
  publisher = {Association for Computing Machinery (ACM)},
  title = {Staged compilation with two-level type theory},
  url = {http://dx.doi.org/10.1145/3547641},
  volume = {6},
  year = {2022},
}

@article{SingleAssignmeScholz2003,
  author = {SCHOLZ, SVEN-BODO},
  doi = {10.1017/s0956796802004458},
  issue = {6},
  journal = {Journal of Functional Programming},
  month = {11},
  pages = {1005--1059},
  publisher = {Cambridge University Press (CUP)},
  title = {Single Assignment C: efficient support for high-level array operations in a functional setting},
  url = {http://dx.doi.org/10.1017/s0956796802004458},
  volume = {13},
  year = {2003},
}

@inproceedings{ScalingComputaAnand2015,
  author = {Anand, Anshu S. and Shyamasundar, R. K.},
  booktitle = {2015 IEEE 22nd International Conference on High Performance Computing Workshops (HiPCW)},
  doi = {10.1109/hipcw.2015.14},
  journal = {2015 IEEE 22nd International Conference on High Performance Computing Workshops},
  month = {12},
  publisher = {IEEE},
  title = {Scaling Computation on GPUs Using Powerlists},
  url = {http://dx.doi.org/10.1109/hipcw.2015.14},
  venue = {Bengaluru, India},
  year = {2015},
}

@article{MultiDimensionSinkar2020,
  author = {\v{S}inkarovs, Artjoms},
  doi = {10.4204/eptcs.317.4},
  journal = {Electronic Proceedings in Theoretical Computer Science},
  language = {en},
  month = {5},
  pages = {57--71},
  publisher = {Open Publishing Association},
  title = {Multi-dimensional Arrays with Levels},
  url = {http://dx.doi.org/10.4204/eptcs.317.4},
  volume = {317},
  year = {2020},
}

@inproceedings{SciqlZhang2013,
  author = {Zhang, Ying and Kersten, Martin and Manegold, Stefan},
  booktitle = {SIGMOD/PODS'13: International Conference on Management of Data},
  doi = {10.1145/2463676.2463684},
  journal = {Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data},
  month = {6},
  publisher = {ACM},
  title = {SciQL},
  url = {http://dx.doi.org/10.1145/2463676.2463684},
  venue = {New York New York USA},
  year = {2013},
}

@article{JuliaAFreshBezans2017,
  author = {Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B.},
  doi = {10.1137/141000671},
  issue = {1},
  journal = {SIAM Review},
  language = {en},
  month = {1},
  pages = {65--98},
  publisher = {Society for Industrial \& Applied Mathematics (SIAM)},
  title = {Julia: A Fresh Approach to Numerical Computing},
  url = {http://dx.doi.org/10.1137/141000671},
  volume = {59},
  year = {2017},
}

@article{AcceleratorTardit2006,
  abstract = {<jats:p>GPUs are difficult to program for general-purpose uses. Programmers can either learn graphics APIs and convert their applications to use graphics pipeline operations or they can use stream programming abstractions of GPUs. We describe Accelerator, a system that uses data parallelism to program GPUs for general-purpose uses instead. Programmers use a conventional imperative programming language and a library that provides only high-level data-parallel operations. No aspects of GPUs are exposed to programmers. The library implementation compiles the data-parallel operations on the fly to optimized GPU pixel shader code and API calls.We describe the compilation techniques used to do this. We evaluate the effectiveness of using data parallelism to program GPUs by providing results for a set of compute-intensive benchmarks. We compare the performance of Accelerator versions of the benchmarks against hand-written pixel shaders. The speeds of the Accelerator versions are typically within 50\% of the speeds of hand-written pixel shader code. Some benchmarks significantly outperform C versions on a CPU: they are up to 18 times faster than C code running on a CPU.</jats:p>},
  author = {Tarditi, David and Puri, Sidd and Oglesby, Jose},
  doi = {10.1145/1168919.1168898},
  issue = {5},
  journal = {ACM SIGARCH Computer Architecture News},
  language = {en},
  month = {10},
  pages = {325--335},
  publisher = {Association for Computing Machinery (ACM)},
  title = {Accelerator},
  url = {http://dx.doi.org/10.1145/1168919.1168898},
  volume = {34},
  year = {2006},
}

@inproceedings{CompilingAplTBudde2015,
  author = {Budde, Michael and Dybdal, Martin and Elsman, Martin},
  booktitle = {PLDI '15: ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/2774959.2774966},
  journal = {Proceedings of the 2nd ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming},
  month = {6},
  publisher = {ACM},
  title = {Compiling APL to accelerate through a typed array intermediate language},
  url = {http://dx.doi.org/10.1145/2774959.2774966},
  venue = {Portland OR USA},
  year = {2015},
}

@techreport{AsapAsStaticProust2017,
  author = {Proust, Rapha\"{e}l L},
  institution = {University of Cambridge, Computer Laboratory},
  title = {Asap: As static as possible memory management},
  year = {2017},
}

@inproceedings{GeneratingPortRasch2019,
  author = {Rasch, Ari and Schulze, Richard and Gorlatch, Sergei},
  booktitle = {2019 28th International Conference on Parallel Architectures and Compilation Techniques (PACT)},
  doi = {10.1109/pact.2019.00035},
  journal = {2019 28th International Conference on Parallel Architectures and Compilation Techniques (PACT)},
  month = {9},
  publisher = {IEEE},
  title = {Generating Portable High-Performance Code via Multi-Dimensional Homomorphisms},
  url = {http://dx.doi.org/10.1109/pact.2019.00035},
  venue = {Seattle, WA, USA},
  year = {2019},
}

@inproceedings{UnleashingGpusHaavis2022,
  author = {Haavisto, Juuso and Cholez, Thibault and Riekki, Jukka},
  booktitle = {NOMS 2022-2022 IEEE/IFIP Network Operations and Management Symposium},
  doi = {10.1109/noms54207.2022.9789822},
  journal = {NOMS 2022-2022 IEEE/IFIP Network Operations and Management Symposium},
  month = {4},
  publisher = {IEEE},
  title = {Unleashing GPUs for Network Function Virtualization: an open architecture based on Vulkan and Kubernetes},
  url = {http://dx.doi.org/10.1109/noms54207.2022.9789822},
  venue = {Budapest, Hungary},
  year = {2022},
}

@article{ProgrammingLanHutton2023,
  abstract = {<jats:title>Abstract</jats:title>
	  <jats:p>Programming language semantics is an important topic in theoretical computer science, but one that beginners often find challenging. This article provides a tutorial introduction to the subject, in which the language of integers and addition is used as a minimal setting in which to present a range of semantic concepts in simple manner. In this setting, it is easy as 1,2,3.</jats:p>},
  author = {HUTTON, GRAHAM},
  doi = {10.1017/s0956796823000072},
  journal = {Journal of Functional Programming},
  language = {en},
  month = {10},
  publisher = {Cambridge University Press (CUP)},
  title = {Programming language semantics: It's easy as 1,2,3},
  url = {http://dx.doi.org/10.1017/s0956796823000072},
  volume = {33},
  year = {2023},
}

@article{ContinuationPaGibbon2021,
  author = {Gibbons, Jeremy},
  doi = {10.22152/programming-journal.org/2022/6/7},
  issue = {2},
  journal = {The Art, Science, and Engineering of Programming},
  language = {en},
  month = {11},
  publisher = {Aspect-Oriented Software Association (AOSA)},
  title = {Continuation-Passing Style, Defunctionalization, Accumulations, and Associativity},
  url = {http://dx.doi.org/10.22152/programming-journal.org/2022/6/7},
  volume = {6},
  year = {2021},
}

@inproceedings{MemoryOptimizaMunksg2022,
  abstract = {We present a technique for introducing and optimizing the use of memory in a functional array language, aimed at GPU execution, that supports correct-by-construction parallelism. Using linear memory access descriptors as building blocks, we define a notion of memory in the compiler IR that enables cost-free change-of-layout transformations (e.g., slicing, transposition), whose results can even be carried across control flow such as ifs/loops without manifestation in memory. The memory notion allows a graceful transition to an unsafe IR that is automatically optimized (1) to mix reads and writes to the same array inside a parallel construct, and (2) to map semantically different arrays to the same memory block. The result is code similar to what imperative users would write. Our evaluation shows that our optimizations have significant impact (1.1\textbackslash{}texttimes\lbrace{}\rbrace{}-2\textbackslash{}texttimes\lbrace{}\rbrace{}) and result in performance competitive to hand-written code from challenging benchmarks, such as Rodinia's NW, LUD, Hotspot.},
  author = {Munksgaard, Philip and Henriksen, Troels and Sadayappan, Ponnuswamy and Oancea, Cosmin},
  booktitle = {Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
  isbn = {9784665454445},
  keywords = {optimizing compiler, parallelism, GPU, functional programming},
  location = {Dallas, Texas},
  publisher = {IEEE Press},
  series = {SC '22},
  title = {Memory Optimizations in an Array Language},
  year = {2022},
}

@inproceedings{IndustrialDeplDonald2023,
  author = {Donaldson, Alastair F. and Clayton, Ben and Harrison, Ryan and Mohsin, Hasan and Neto, David and Teliman, Vasyl and Watson, Hana},
  booktitle = {2023 IEEE Conference on Software Testing, Verification and Validation (ICST)},
  doi = {10.1109/icst57152.2023.00042},
  journal = {2023 IEEE Conference on Software Testing, Verification and Validation (ICST)},
  month = {4},
  publisher = {IEEE},
  title = {Industrial Deployment of Compiler Fuzzing Techniques for Two GPU Shading Languages},
  url = {http://dx.doi.org/10.1109/icst57152.2023.00042},
  venue = {Dublin, Ireland},
  year = {2023},
}

@inproceedings{UNetCnnInApHsuA2023,
  author = {Hsu, Aaron W. and Serr\~{a}o, Rodrigo Gir\~{a}o},
  booktitle = {ARRAY '23: 9th ACM SIGPLAN International Workshop on Libraries, Languages and Compilers for Array Programming},
  doi = {10.1145/3589246.3595371},
  journal = {Proceedings of the 9th ACM SIGPLAN International Workshop on Libraries, Languages and Compilers for Array Programming},
  month = {6},
  publisher = {ACM},
  title = {U-Net CNN in APL: Exploring Zero-Framework, Zero-Library Machine Learning},
  url = {http://dx.doi.org/10.1145/3589246.3595371},
  venue = {Orlando FL USA},
  year = {2023},
}

@article{OperatorsAndFKennet1978,
  author = {Kenneth Iverson},
  title = {Operators and Functions},
  url = {https://www.jsoftware.com/papers/opfns.htm},
  year = {1978},
}

@inproceedings{OnMappingNDiJansse2021,
  author = {Janssen, Niek and Scholz, Sven-Bodo},
  booktitle = {IFL '21: 33rd Symposium on Implementation and Application of Functional Languages},
  doi = {10.1145/3544885.3544894},
  journal = {33rd Symposium on Implementation and Application of Functional Languages},
  month = {9},
  publisher = {ACM},
  title = {On Mapping N-Dimensional Data-Parallelism Efficiently into GPU-Thread-Spaces},
  url = {http://dx.doi.org/10.1145/3544885.3544894},
  venue = {Nijmegen Netherlands},
  year = {2021},
}

@inproceedings{CombinatoryLogHoekst2022,
  author = {Hoekstra, Conor},
  booktitle = {ARRAY '22: 8th ACM SIGPLAN International Workshop on Libraries, Languages and Compilers for Array Programming},
  doi = {10.1145/3520306.3534504},
  journal = {Proceedings of the 8th ACM SIGPLAN International Workshop on Libraries, Languages and Compilers for Array Programming},
  month = {6},
  publisher = {ACM},
  title = {Combinatory logic and combinators in array languages},
  url = {http://dx.doi.org/10.1145/3520306.3534504},
  venue = {San Diego CA USA},
  year = {2022},
}

@inbook{ReflectionsOnAbouS2016,
  author = {Abou-Saleh, Faris and Cheney, James and Gibbons, Jeremy and McKinna, James and Stevens, Perdita},
  doi = {10.1007/978-3-319-30936-1\_1},
  isbn = {['9783319309354', '9783319309361']},
  journal = {A List of Successes That Can Change the World},
  month = {3},
  pages = {1--31},
  publisher = {Springer International Publishing},
  title = {Reflections on Monadic Lenses},
  url = {http://dx.doi.org/10.1007/978-3-319-30936-1\_1},
  year = {2016},
}

@article{ProfunctorOptiRoman,
  abstract = {Optics are bidirectional accessors of data structures; they provide a powerful abstraction of many common data transformations. This abstraction is compositional thanks to a representation in terms of profunctors endowed with an algebraic structure called Tambara module. There exists a general definition of optic in terms of coends that, after some elementary application of the Yoneda lemma, particularizes in each one of the basic optics. Traversals used to be the exception; we show an elementary derivation of traversals and discuss some other new derivations for optics. We relate our characterization of traversals to the previous ones showing that the coalgebras of a comonad that represents and split into shape and contents are traversable functors. The representation of optics in terms of profunctors has many different proofs in the literature; we discuss two ways of proving it, generalizing both to the case of mixed optics for an arbitrary action. Categories of optics can be seen as Eilenberg-Moore categories for a monad described by Pastro and Street. This gives us two different approaches to composition between profunctor optics of different families: using distributive laws between the monads defining them, and using coproducts of monads. The second one is the one implicitly used in Haskell programming; but we show that a refinement of the notion of optic is required in order to model it faithfully. We provide experimental implementations of a library of optics in Haskell and partial Agda formalizations of the profunctor representation theorem.},
  author = {Rom\'{a}n, Mario},
  doi = {10.48550/arXiv.2001.08045},
  title = {Profunctor optics and traversals},
  url = {https://arxiv.org/abs/2001.08045v1},
}

@article{ProfunctorOptiPicker,
  abstract = {CONTEXT: Data accessors allow one to read and write components of a data structure, such as the fields of a record, the variants of a union, or the elements of a container. These data accessors are collectively known as optics; they are fundamental to programs that manipulate complex data. INQUIR...},
  author = {Pickering, Matthew and Gibbons, Jeremy and Wu, Nicolas},
  doi = {10.22152/programming-journal.org/2017/1/7},
  issn = {2473-7321},
  issue = {2},
  journal = {The Art, Science, and Engineering of Programming},
  language = {en},
  publisher = {AOSA, Inc.},
  title = {Profunctor Optics: Modular Data Accessors},
  url = {https://programming-journal.org/2017/1/7/},
  volume = {1},
}

@article{CostingParalleJayC2000,
  abstract = {Portable, efficient, parallel programming requires cost models to compare different possible implementations. In turn, these require knowledge of the shapes of the data structures being used, as well as knowledge of the hardware parameters. This paper shows how shape analysis techniques developed in the FISh programming language could be exploited to produce a data parallel language with an accurate, portable cost model.},
  author = {Jay, C.Barry},
  doi = {https://doi.org/10.1016/S0167-6423(99)00027-1},
  issn = {0167-6423},
  journal = {Science of Computer Programming},
  number = {1},
  pages = {207-224},
  title = {Costing parallel programs as a function of shapes},
  url = {https://www.sciencedirect.com/science/article/pii/S0167642399000271},
  volume = {37},
  year = {2000},
}

@inproceedings{CompositionalGGhani2018,
  abstract = {We introduce open games as a compositional foundation of economic game theory. A compositional approach potentially allows methods of game theory and theoretical computer science to be applied to large-scale economic models for which standard economic tools are not practical. An open game represents a game played relative to an arbitrary environment and to this end we introduce the concept of coutility, which is the utility generated by an open game and returned to its environment. Open games are the morphisms of a symmetric monoidal category and can therefore be composed by categorical composition into sequential move games and by monoidal products into simultaneous move games. Open games can be represented by string diagrams which provide an intuitive but formal visualisation of the information flows. We show that a variety of games can be faithfully represented as open games in the sense of having the same Nash equilibria and off-equilibrium best responses.},
  address = {New York, NY, USA},
  author = {Ghani, Neil and Hedges, Jules and Winschel, Viktor and Zahn, Philipp},
  booktitle = {Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science},
  doi = {10.1145/3209108.3209165},
  isbn = {9781450355834},
  location = {Oxford, United Kingdom},
  pages = {472\textendash{}481},
  publisher = {Association for Computing Machinery},
  series = {LICS '18},
  title = {Compositional Game Theory},
  url = {https://doi.org/10.1145/3209108.3209165},
  year = {2018},
}

@article{AFoundationFoKleffn,
  abstract = {The design space for concatenative programming languages, also known as stack-based programming languages, is largely under-explored. Most formal investigations of higher-order stack-based languages are done in the functional setting, requiring a cumbersome and unnecessary encoding. This dissertation describes a core programming language that captures the essence of the concatenative paradigm, provides a reduction semantics for this language, and introduces a sound type system. It also presents a sound and complete type inference algorithm. We expect that this model will serve as a starting point for future explorations of the concatenative language design space.--Author's abstract},
  author = {Kleffner, Robert},
  doi = {10.17760/D20467250},
  keywords = {concatenative programming, stack-based languages, type inference, Computer science},
  title = {A foundation for typed concatenative languages},
  url = {https://doi.org/10.17760/D20467250},
}

@article{ResearchDirectHammon1999,
  author = {Hammond, Kevin and Michaelson, Greg},
  isbn = {9781852330927},
  language = {},
  publisher = {Springer-Verlag},
  title = {Research Directions in Parallel Functional Programming},
  year = {1999},
}

@article{ShapeInComputJayC1996,
  author = {Jay, C. Barry},
  doi = {10.1145/234528.234749},
  issue = {2},
  journal = {ACM Computing Surveys},
  language = {en},
  month = {6},
  pages = {355--357},
  publisher = {Association for Computing Machinery (ACM)},
  title = {Shape in computing},
  url = {http://dx.doi.org/10.1145/234528.234749},
  volume = {28},
  year = {1996},
}

@article{ASemanticsForJayC1995,
  abstract = {Shapely types separate data, represented by lists, from shape, or structure. This separation supports shape polymorphism, where operations are defined for arbitrary shapes, and shapely operations, for which the shape of the result is determined by that of the input, permitting static shape checking. The shapely types are closed under the formation of fixpoints, and hence include the usual algebraic types of lists, trees, etc. They also include other standard data structures such as arrays, graphs and records.},
  author = {Jay, C.Barry},
  doi = {https://doi.org/10.1016/0167-6423(95)00015-1},
  issn = {0167-6423},
  journal = {Science of Computer Programming},
  note = {Selected Papers of ESOP'94, the 5th European Symposium on Programming},
  number = {2},
  pages = {251-283},
  title = {A semantics for shape},
  url = {https://www.sciencedirect.com/science/article/pii/0167642395000151},
  volume = {25},
  year = {1995},
}

@article{WaitFreeSynchHerlih,
  abstract = {A wait-free implementation of a concurrent data object is one that guarantees that any process can complete any operation in a finite number of steps, regardless of the execution speeds of the othe...},
  author = {HerlihyMaurice, },
  date = {1991-01-01},
  doi = {10.1145/114005.102808},
  journal = {ACM Transactions on Programming Languages and Systems (TOPLAS)},
  keywords = {linearization; wait-free synchronization},
  language = {EN},
  publisher = {ACMPUB27New York, NY, USA},
  title = {Wait-free synchronization},
  url = {https://dl.acm.org/doi/10.1145/114005.102808},
}

@inproceedings{FullyAnonymousRaynal2020,
  abstract = {Process anonymity has been studied for a long time. Memory anonymity is more recent. In an anonymous memory system, there is no a priori agreement among the processes on the names of the shared registers they access. As an example, a shared register named A by a process p and a shared register named B by another process q may correspond to the very same register X, while the same name C may correspond to different shared registers for the processes p and q. This article focuses on solving the consensus and set agreement problems in the fully anonymous model, namely a model in which both the processes and the registers are anonymous. It is shown that consensus, and its weak version called set agreement, can be solved despite full anonymity, in the presence of any number of process crashes. As far as we know, this is the first time where non-trivial concurrency-related problems are solved in such a strong anonymity context. A noteworthy property of the proposed algorithms lies in their conceptual simplicity.},
  address = {Berlin, Heidelberg},
  author = {Raynal, Michel and Taubenfeld, Gadi},
  booktitle = {Networked Systems: 8th International Conference, NETYS 2020, Marrakech, Morocco, June 3\textendash{}5, 2020, Proceedings},
  doi = {10.1007/978-3-030-67087-0\_20},
  isbn = {978-3-030-67086-3},
  keywords = {Anonymity, Anonymous shared memory, Anonymous processes, Asynchrony, Atomic read/write register, Atomic read/modify/write register, Concurrency, Consensus, Crash failure, Process crash, Set agreement, Obstruction-freedom, Wait-freedom},
  location = {Marrakech, Morocco},
  pages = {314\textendash{}328},
  publisher = {Springer-Verlag},
  title = {Fully Anonymous Consensus and Set Agreement Algorithms},
  url = {https://doi.org/10.1007/978-3-030-67087-0\_20},
  year = {2020},
}

@inproceedings{NonBlockingArShafie2009,
  abstract = {We present new non-blocking array-based shared stack and queue implementations. We sketch proofs of correctness and amortized time analyses for the algorithms. To the best of our knowledge, our stack algorithm is the first practical array-based one and it is the first time that bounded counter values are employed to implement a shared stack and queue. We verify the correctness of our algorithms by the Spin model checker and compare our algorithms to other algorithms experimentally.},
  address = {Berlin, Heidelberg},
  author = {Shafiei, Niloufar},
  booktitle = {Distributed Computing and Networking},
  editor = {Garg, Vijay
and Wattenhofer, Roger
and Kothapalli, Kishore},
  isbn = {978-3-540-92295-7},
  pages = {55--66},
  publisher = {Springer Berlin Heidelberg},
  title = {Non-blocking Array-Based Algorithms for Stacks and Queues},
  year = {2009},
}

@article{ConcurrentProgRaynal2012,
  author = {Raynal, Michel},
  isbn = {9783642320262},
  language = {},
  publisher = {Springer},
  title = {Concurrent Programming - Algorithms, Principles, and Foundations},
  year = {2012},
}

@inproceedings{RelationalLensBohann2006,
  author = {Bohannon, Aaron and Pierce, Benjamin C. and Vaughan, Jeffrey A.},
  booktitle = {SIGMOD/PODS06: International Conference on Management of Data and Symposium on Principles Database and Systems},
  doi = {10.1145/1142351.1142399},
  journal = {Proceedings of the twenty-fifth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems},
  month = {6},
  publisher = {ACM},
  title = {Relational lenses},
  url = {http://dx.doi.org/10.1145/1142351.1142399},
  venue = {Chicago IL USA},
  year = {2006},
}

@article{RndnFastQuerKrolik2023,
  abstract = {<jats:p>GPU database systems are an effective solution to query optimization, particularly with compilation and data caching. They fall short, however, in end-to-end workloads, as existing compiler toolchains are too expensive for use with short-running queries. In this work, we define and evaluate a runtime-suitable query compilation pipeline for NVIDIA GPUs that extracts high performance with only minimal optimization. In particular, our balanced approach successfully trades minor slowdowns in execution for major speedups in compilation, even as data sizes increase. We demonstrate performance benefits compared to both CPU and GPU database systems using interpreters and compilers, extending query compilation for GPUs beyond cached use cases.</jats:p>},
  author = {Krolik, Alexander and Verbrugge, Clark and Hendren, Laurie},
  doi = {10.1145/3603503},
  issue = {3},
  journal = {ACM Transactions on Architecture and Code Optimization},
  language = {en},
  month = {9},
  pages = {1--25},
  publisher = {Association for Computing Machinery (ACM)},
  title = {rNdN: Fast Query Compilation for NVIDIA GPUs},
  url = {http://dx.doi.org/10.1145/3603503},
  volume = {20},
  year = {2023},
}

@inproceedings{AnArrayOrientSlepak2014,
  abstract = {The array-computational model pioneered by Iverson's languages APL and J offers a simple and expressive solution to the \textasciigrave{}\textasciigrave{}von Neumann bottleneck.'' It includes a form of rank, or dimensional, polymorphism, which renders much of a program's control structure implicit by lifting base operators to higher-dimensional array structures. We present the first formal semantics for this model, along with the first static type system that captures the full power of the core language.},
  address = {Berlin, Heidelberg},
  author = {Slepak, Justin and Shivers, Olin and Manolios, Panagiotis},
  booktitle = {Programming Languages and Systems},
  editor = {Shao, Zhong},
  isbn = {978-3-642-54833-8},
  pages = {27--46},
  publisher = {Springer Berlin Heidelberg},
  title = {An Array-Oriented Language with Static Rank Polymorphism},
  year = {2014},
}

@phdthesis{ThePurelyFuncDolstr2006,
  address = {Utrecht, The Netherlands},
  author = {Dolstra, Eelco},
  month = {January},
  school = {Utrecht University},
  title = {The Purely Functional Software Deployment Model},
  year = {2006},
}
